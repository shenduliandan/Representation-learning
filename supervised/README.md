# Research
1. CLIPï¼š[Paper](https://arxiv.org/abs/2103.00020) [Code](https://github.com/openai/CLIP)
2. ViLD: [Paper](https://arxiv.org/abs/2104.13921) [Code](https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild)
3. CLIP-Adapter: [Paper](https://arxiv.org/abs/2110.04544) [Code](https://github.com/gaopengcuhk/clip-adapter)
4. CLIP4Caption: [Paper](https://arxiv.org/abs/2110.06615) [Code]()
5. A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model: [Paper](https://arxiv.org/abs/2112.14757) [Code](https://github.com/MendelXu/zsseg.baseline)
